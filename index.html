<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Dubbing for Everyone allows for fast and data effecient visual dubbing for all actors using person-generic priors.">
  <meta name="keywords" content="Neural Rendering, Deepfake, Talking Head, Dubbing">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Dubbing for Everyone: Data-Efficient Visual Dubbing using Neural Rendering Priors</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-8RPX3Y5R3H"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-8RPX3Y5R3H');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://jsaunders909.github.io/">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://jsaunders909.github.io/">
            Coming Soon!
          </a>
        </div>
      </div>
    </div>


  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Dubbing for Everyone: Data-Efficient Visual Dubbing using Neural Rendering Priors</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://jsaunders909.github.io/">Jack Saunders</a></span>
              <span class="author-block">
                <a href="https://vinaypn.github.io/">Vinay P. Namboodiri</a></span>
            </div>
  
            <div class="is-size-5 publication-authors">
              <span class="author-block">University of Bath,</span>
            </div>
  

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. Add href after a -->
              <span class="link-block">
                <a
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a 
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=mnlWVLLoeiY"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img id="teaser" height="100%" src="./static/images/D4E.png">
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">Dubbing for Everyone</span> allows for effecient visual dubbing with as little as 4s of data.
      </h2>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
          Visual dubbing is the process of generating lip motions of an actor in a video to synchronise with given audio.
          Visual dubbing allows video-based media to reach global audiences. Recent advances have made progress towards realising
          this goal but have not been able to produce an approach suitable for mass adoption. 
          </p>
          <p>
          Existing methods are split into either person-generic or person-specific models. 
          Person-specific models produce results almost indistinguishable from reality but rely on long training 
          times using large single-person datasets. Person-generic works have allowed for the visual dubbing of any video
          to any audio without further training, but these fail to capture the person-specific characteristics and 
          often suffer from visual artefacts. Our methodology, based on data-efficient neural rendering priors, 
          overcomes the limitations of existing approaches. Our pipeline consists of learning a deferred neural rendering
          prior network and actor-specific adaptation using neural textures. This method allows for 
          <b>high-quality visual dubbing with just a few seconds of data</b>, 
          that enables video dubbing for any actor - from A-list celebrities to background actors. 
          </p> 
          <p>
          We show that we achieve state-of-the-art in terms of <b style="color:blue;">visual quality</b> and 
          <b style="color:red;">recognisability</b> both quantitatively, and qualitatively through two user studies. 
          Our prior learning and adaptation method <b style="color:rgb(7, 129, 48);">generalises to limited data</b> better and is more
          <b style="color:orange;">scalable</b> than existing person-specific models. Our experiments on a real-world, 
          limited data scenarios find that our model is preferred over all existing methodologies. 
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/mnlWVLLoeiY?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div>
    <!--/ Paper video. -->
  </div>
</section>

<section class="section" id="Method">
  <div class="columns is-centered has-text-centered">
    <div class="column is-four-fifths">
      <h2 class="title is-3">Method</h2>
      <img src="./static/images/Methodology.png">
      <div class="content has-text-justified">
        <p>
        The pipeline of our method. We first apply preprocessing to our dataset to obtain 3D reconstructions, tightly
        and stably cropped to the face. We next obtain person-generic audio-to-expression and neural rendering models 
        using multiple subjects.
        Given a new subject, we then finetune both models for the given subject.
      </p>
    </div>
    </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{Saunders2024D4E,
  author    = {Saunders, Jack and Namboodiri, Vinay},
  title     = {Dubbing for Everyone: Data-Efficient Visual Dubbing using Neural Rendering Priors},
  journal   = {arxiv},
  year      = {2024},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href>
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link"  class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
